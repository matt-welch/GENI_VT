\chapter{Results}
\label{cha:results}
\label{sec:results}
Network performance of docker containers and virtual machines was analyzed using standard benchmarking tools including netperf and ping.  
Twenty measurements were taken for each type of virtual environment using the standard 3.18.20 kernel and the preempt-rt tuned kernel.
For each kernel, virtual environment, and network conenction type, the latency and bandwidth of both TCP and UDP streams were measured 20 times along with 100 measurements of ICMP latency.
The data is shown in all STREAM and RR figures as box plots with the median in the center, 25th and 75th percentiles at the bottom and top bounds of the box and min and max at the ends of the error bars.
This plot helps to illustrate the one-sided variance that may often be observed in network performance anaylsis.  
The measurements can only approach the theoretical maxima for each test.  

Variation in the measured latency is partly due to the non-determinism of typical Linux systems, but there is also a component of the latency due only to the network delays.
The 10 Gbps optical cables connecting the two systems are approximately 2 meters long so the propagation delay along these connections should be about 6.7 ns.
In-network queueing delay can be ignored since the systems are directly connected and queuing is only occurring at their network interfaces.
The transmission or packetization delay for transmitting or receiving a large 1500 byte packet would be 1.214 $\mu$s.

\begin{table}[ht!]
    \centering
    \begin{tabular}{|l|c|c|}
    \hline
    Parameter & variants & \\
    \hline \hline
    kernel & 3.18.20 & 3.18.20-rt18 \\ 
    environment & docker & KVM \\ 
    network interface & bridge & physical \\ 
    \hline
    \end{tabular}
\end{table}

\section{Network Bandwidth} % (fold)
\label{sec:networkbandwidth}
Given the 
\subsection{TCP Bandwidth} % (fold)
\label{sub:tcpbandwidth}
TCP bandwidth of the various network interfaces and kernels was measured using the TCP\_STREAM bandwidth test in netperf.
The results of the bridged measurements are shown in Figure~\ref{fig:tcp_stream_bridge} where it is evident that, while both environments show significant variation with standard kernels, the realtime-variant kernels show only minimal variance and the docker-rt test even reached line rate.
The performance of both the container and virtual machine, with minima close to the median and maxima only slightly above that point, are consistent with a realtime kernel in that the performance is essentially deterministic with little variance (TODO: cite variance or figure??).

The results of the physical connection measurements are shown in Figure~\ref{fig:tcp_stream_phys}.
\begin{figure}
    \centering
    \def\svgwidth{\columnwidth}
    \input{TCP_STREAM_PHY.pdf_tex}
    \caption{TCP Streaming Bandwidth: Physical Network}
    \label{fig:tcp_stream_phys}
\end{figure}
\begin{figure}
    \centering
    \def\svgwidth{\columnwidth}
    \input{TCP_STREAM_BRG.pdf_tex}
    \caption{TCP Streaming Bandwidth: Bridged Network}
    \label{fig:tcp_stream_bridge}
\end{figure}
% subsection tcpbandwidth (end)

\subsection{UDP Bandwidth} % (fold)
\label{sub:udpbandwidth}
\begin{figure}
    \centering
    \def\svgwidth{\columnwidth}
    \input{UDP_STREAM_BRG.pdf_tex}
    \caption{UDP Streaming Bandwidth: Bridged Network}
    \label{fig:udp_stream_bridge}
\end{figure}
\begin{figure}
    \centering
    \def\svgwidth{\columnwidth}
    \input{UDP_STREAM_PHY.pdf_tex}
    \caption{UDP Streaming Bandwidth: Physical Network}
    \label{fig:udp_stream_phys}
\end{figure}
% subsection udpbandwidth (end)


% section networkbandwidth (end)

\section{Network Latency} % (fold)
\label{sec:networklatency}

\subsection{TCP Latency} % (fold)
\label{sub:tcplatency}
\begin{figure}
    \centering
    \def\svgwidth{\columnwidth}
    \input{TCP_RR_BRG.pdf_tex}
    \caption{TCP Request/Response Latency: Bridged Network}
    \label{fig:tcp_rr_bridge}
\end{figure}
\begin{figure}
    \centering
    \def\svgwidth{\columnwidth}
    \input{TCP_RR_PHY.pdf_tex}
    \caption{TCP Request/Response Latency: Physical Network}
    \label{fig:tcp_rr_phys}
\end{figure}

% subsection tcplatency (end)

\subsection{UDP Latency} % (fold)
\label{sub:udplatency}
\begin{figure}
    \centering
    \def\svgwidth{\columnwidth}
    \input{UDP_RR_BRG.pdf_tex}
    \caption{UDP Request/Response Latency: Bridged Network}
    \label{fig:udp_rr_bridge}
\end{figure}
\begin{figure}
    \centering
    \def\svgwidth{\columnwidth}
    \input{UDP_RR_PHY.pdf_tex}
    \caption{UDP Request/Response Latency: Physical Network}
    \label{fig:udp_rr_phys}
\end{figure}
% subsection udplatency (end)

%\subsection{ICMP latency} % (fold)
\label{sub:icmplatency}
The standard network tool ping was used to get an idea of the layer 3 latency of the virtual hosts.  
The box-plot results of the ping testing of the bridged connections are shown in Figure~\ref{fig:icmplatencybridge}.  
The box-plot results of the ping testing of the physical connections are shown in Figure~\ref{fig:icmplatencyphys}.  
\begin{figure}
    \centering
    \def\svgwidth{\columnwidth}
    \input{ICMP_LAT_BRG.pdf_tex}
    \caption{ICMP latency: Bridged network}
    \label{fig:icmplatencybridge}
\end{figure}
\begin{figure}
    \centering
    \def\svgwidth{\columnwidth}
    \input{ICMP_LAT_PHY.pdf_tex}
    \caption{ICMP latency: Physical network}
    \label{fig:icmplatencyphys}
\end{figure}
% subsection icmplatency (end)

% section networklatency (end)
