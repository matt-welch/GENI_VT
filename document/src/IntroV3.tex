\chapter{Introduction}
\label{sec:introduction}

\section{Motivation} % (fold)
\label{sec:motivation}
% virtualization is an important technology in many industries including cloud, NFV, HPC (upcoming), and realtime (upcoming).
Containers are becoming one of the most common mechanisms for deploying applications and maximizing hardware utilization.
Virtual machines have been used in enterprise uses for years and have recently grown dramatically as the cloud computing paradigm and Network function virtualization (NFV) have expanded\autocite{cohnopnfv, opnfv1}.
In this context, the term ``virtual system'' can refer to virtualization technologies including both virtual machines and containers.
Growth has been strong in cloud services for good reason as described by Young et al.~\autocite{_younge_1}.
In that work, they describe many of the benefits offered by cloud services such as scalability, controlling quality of service (QoS), customization of user infrastructure, cost effectiveness, and simplified access interfaces, almost all of which are enabled by virtualization.  
In NFV, the functionality that is often embodied in physical devices such as routers, firewalls, and load balancers may be accomplished with a virtual system which increases flexibility and scalability of the network in many cases.
In anticipation of this industry transformation, trade organizations have recently sprouted up to promote NFV adoption and accelerate its development.
Both the European Telecommunications Standards Institute (ETSI) and Open Platform for Network Function Virtualization (OPNFV) have been formed for that purpose \autocite{opnfv1, cohnopnfv}.
Developments in containers also enable excellent tools for process isolation and application portability, inspiring system designers to reconsider how these technologies fit into the virtualization ecosystem.

% VT growing into HPC and workloads with high sensitivity to latency and jitter
Studies examining the suitability of virtualization for cloud, NFV, and high performance computing (HPC) applications, often cite low input/output (I/O) performance as a factor limiting overall performance~\autocite{xavier2013performance, _younge_1, des2005virtualization}.
These same I/O constraints also limit application scalability in HPC systems due to the high latency of inter-node communication.
%\TODO tie these sentences together
The Linux Foundation is the body that guides and sponsors the direction of Linux so their interest comes at an important time due to recent funding difficulties for realtime Linux \autocite{_lwn_1}.
The developments and interest in realtime will help improve the latency and jitter of virtual machines which is one of their greatest weaknesses, particularly with respect to I/O.
The improved determinism of a system running with realtime performance enables applications that were not previously possible in virtual systems.
Innovations in realtime and HPC can also improve NFV and cloud performance by making these systems more responsive and predictable.

% what are current limitations on VT and containers?
An important motivation for virtualization is to increase process density which improves hardware utilization, bringing down costs.
Density of processes and applications may be increased even further by utilizing containers such as Docker \autocite{dockerdotcom}.
Although containers have potential to scale to hundreds or thousands of containers per host, these special cases are often not possible without specific homogeneous workloads.
Memory contention and I/O density are often limiting factors in system performance such that process density can not increase without addressing memory and I/O limitations.
Containers can very efficiently share and utilize available CPU and memory resources, but scalability is limited for containers that need high bandwidth or low latency network communication
% section motivation (end)

\section{Contributions} % (fold)
\label{sec:introcontributiions}
% performance comparisons have not tried to improve performance
Many studies have analyzed virtual machines and containers to compare their performance \autocite{soltesz2007container, matthews2007quantifying, gomes2014performance, seo2014performance, morabitohypervisors, xavier2013performance, _felter_1, rathore2013kvm, _scheepers_1, wangAllocation2007, _younge_1, _che_}.
These studies have been performed valuable analyses of these systems and provided significant insight into their performance issues.
The context for these studies are commonly in the context of cloud computing, NFV, or HPC.
In these contexts, network performance is important due to the cooperative nature of the network in a large-scale system.
These studies usually find that I/O is an issue, yet no modification is suggested by their authors to improve its performance.
The systems analyzed in those studies differ little from their ``factory defaults'', which produces results that ignore real-world deployments and goals such as maximizing performance.

Tuning can be a challenging task due to poorly-defined endpoints and deeply-connected dependencies between options which complicate assessing the benefit of a particular choice.
This is further complicated by the nondeterministic nature of operating systems which may hide the effects of certain types of tuning.
Many system parameters, however, have well-known benefits or penalties such as addressing known bottlenecks in memory and I/O.  
Improving the performance of I/O is complicated by difficulties in sharing and scalability problems that accompany bridging and similar paradigms.

% I tried to improve performance with standard tools, techniques, process isolation
The results of previous comparisons are built upon here by demonstrating a straightforward, logical tuning process that addresses CPU, memory, and I/O performance enhancements to improve network performance.
Performance improvement is accomplished through patching the host and guest kernels with the \texttt{preempt-rt} patch-set~\autocite{preemptrtpatches}.
The \texttt{preempt-rt} kernel is further tuned by applying specific boot options to improve its process isolation and virtual memory performance.
The tuning and \texttt{preempt-rt} patching mentioned above are applied to the Linux \texttt{3.18.20} kernel to produce the \texttt{3.18.20-rt18 PREEMPT-RT} kernel which is then built with specific configuration choices to enhance performance. 
The \texttt{preempt-rt} tuned kernel improves the determinism of both virtual machines and containers.
The Linux kernel is the main focus of tuning here without modification of hardware parameters to provide benefits that can be realized on the majority of modern hardware.

This work compares the performance of the two kernels running popular open-source virtual systems including kernel virtual machine (KVM) and Docker \autocite{dockerdotcom}.
No feedback-driven optimizations are performed in favor of making informed, logical choices to improve performance.
The network performance of bridged and physical network interfaces is measured using common open-source tools such as \texttt{netperf}.
Testing completed with \texttt{netperf} includes measurement of TCP and UDP bandwidth, along with TCP, UDP and ICMP latency.
% section introcontributiions (end)

% describe results.
This thesis demonstrates that modifications to the kernel can improve network variance significantly.  
One result of note is variance in TCP bandwidth decreased as much as 97\% for containers using bridged networking.
In some cases, system tuning and process isolation can increase performance as well, but the primary goal of this work is to reduce variance in bandwidth and latency.
The results of this work show that tuning may offer greater benefits to options like bridged networking more than physical network interfaces due to the improved determinism of the kernel and improved process isolation that results from tuning.
Physical interfaces, in contrast, leverage direct memory access (DMA) and CPU virtualization extensions which already limit operating system involvement. 
The work shown here is available for reference at .
The intent of this work is to educate and inspire more systems designed to improve the performance of the virtual system paradigm such that virtual processes may run on any hardware when given sufficient resources.  

\section{Organization} % (fold)
\label{sec:introorganization}

% this thesis is organized like so
This thesis is divided into five chapters, the remainder of which is organized as follows.
Important related work that has enabled performant virtual systems is described in Chapter~\ref{sec:related_work} along with some discussion of the previous performance analyses comparing virtual systems.
Virtual machine and container architecture are also briefly discussed in Chapter~\ref{sec:related_work} to demonstrate areas for improving performance.
Test platform hardware descriptions and a discussion of the operating system modifications made are presented in Chapter~\ref{sec:experimental_design} with motivations for those choices and their intended effects.
The experimental procedures and protocols including the measurement process and types of network tests performed are also discussed there.
Results of the network measurements from Chapter~\ref{sec:experimental_design} are discussed in Chapter~\ref{sec:results} along with their significance and implications.  
Chapter~\ref{sec:conclusions} analyses the results and describes some future work that resulted from the investigation performed here.

% section introorganization (end)
Commonly referred to as a "virtualization penalty", virtual machines often add latency due to increased abstraction layers which can be detrimental to the performance of streaming network flows.
Limitations to overall network throughput of virtual systems can be minimized by increasing system density and using load balancing techniques.
Improvements to bandwidth, however, can hurt latency which increases with contention of shared resources.
In contrast to bandwidth improvements, latency must be addressed with different mechanisms.
Latency in these systems is mitigated with straightforward modifications and configuration changes to existing systems.

