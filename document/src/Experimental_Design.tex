\lstset{basicstyle=\ttfamily\color{black}}
\chapter{Experimental Design}
\label{sec:experimental_design}

As we've seen in the previous sections, the performance comparisons that have been made between containers and virtual machines have, for the most part, not tuned their systems for the comparison.
Indeed, due to the numerous potential parameters and the resulting massive number of configuration combinations, the sheer number of comparisons to be made among the effects of various tuning parameters are myriad.
To avoid this potential explosion in the scope of the comparison, we will compare performance between only two system configurations for each type of virtual environment.
The two configurations include the standard Linux kernel, version 3.18.20, and the same kernel with preempt-rt patches applied [preempt-rt patch reference here] and some important tuning parameters for the kernel and environment.  


Potential section headings include: Design, Architecture, Preempt-RT, Kernel Tuning, Benchmark Analysis, Hardware Utilized, Experimental Setup and Hardware.\\ 

\section{Experimental Setup} % (fold)
\label{sec:experimental_setup}

    \subsection{Hardware} % (fold)
    \label{sec:hardware}
    
    The motherboard 
    Each of the two CPU sockets on the motherboard were populated with an Intel Xeon E5-2608L v3 6-core processor running at 2.00 GHz.  Hyperthreading was disabled in the BIOS as a performance optimization.  
    The platform was configured with 64 GB of DDR4 memory running at 1866 MHz in Dual-channel mode with 2 16GB memory sticks per socket.  
    The network card used was the Intel Corporation 82599ES 10-Gigabit PCIe card with two optical interfaces.  

    Expand on hardware details and BIOS settings including hyperthreading (+reasoning)

    The PCIe network interface cards used were Intel 82599ES with two 10 Gbps optical interface interfaces per card.
    10 Gigabit network interfaces used because almost any virtualization system, be it container or virtual machine, can push 1 Gbps of traffic per core.
    With a 10 Gbps interface, however, the work required to push that bandwidth through the interface means that both the virtual machines and containers should see some performance differences
    % subsection hardware (end)
    
    \subsection{Networking and Topology} % (fold)
    \label{sub:expt_networking}
    There are many varieties of network interfaces avaialable in virtual environments.
    These include both hardware and software options with varying degrees of versatility and performance.  
    Most common among software options, virtual bridges are operated by the host kernel with a non-trivial CPU involvement. 
    Software bridges are also commonly used by virtual machines and often combined with the virtio library \autocite{_virtio_1}. 
    Bridges are the \emph{de facto} layer 2 networking used by Docker.  
    The Docker daemon also uses the common Linux firewall IPTables for layer 3 connectivity, routing, and NAT.
    This implies that bridging or any networking paradigm that requires host kernel involvement cannot scale to a large number of guests because the work required by the host to monitor and handle bridge traffic and layer 3 decisions for multiple guests can be significant.    
        \subsubsection{Software Networking} % (fold)
        \label{ssub:software_networking}
        Docker’s default networking paradigm is to create a bridge and pair of virtual Ethernet interfaces.
        Both interfaces are bound to the bridge, one remains in the host’s namespace and the other is placed in the container namespace as its primary network interface.
        Docker also uses IPTables and Network Address Translation to allow the container to communicate with the outside world.
        IPTables is also going to have an impact on the bridge performance, but we chose to use it since it represents the \emph{de facto} networking configuration of Docker.
        Another reason to study the bridged networking paradigm is that bridges are very important in networking in general and useful in systems where containers may be linked together or their functions pipelined.
        Additionally, the popular software switch package, Open vSwitch (OVS) may be configured to use virtual bridging as its default network topology.
        
        [ insert bridged topology diagram here] 
        No effort was made to optimize the performance of the bridge.
        Parameters including whether the bridge participates in the STP algorithm are optional and can affect performance.
        The focus of this work is not on tuning the network interfaces themselves, however but rather investigates how a latency-sensitive system can be configured to improve performance.

        
        % subsubsection software_networking (end)
        \subsubsection{Hardware networking} % (fold)
        \label{ssub:hardware_networking}
        In order to obtain near-native performance for both virtual machines and containers, a physical interface may be passed from the host into the domain of the virtual machine or into the namespace of the container.
        As we have seen in \S \ref{sec:vt_io}, this is known as passthrough for virtual machines and is supported by CPU virtualization extensions \autocite{_grinberg_1}..
        In the version of Docker used herein, 1.8.1, direct physical assignment is not enabled by default.
        Instead, a fairly simple script was written [prepare\_network\_stack.sh], with inspiration borrowed from Jermoe Petazzoni [reference], and this stack overflow pot [reference] to assign a physical interface to the container namespace. 

        Another network interface that may be provided to a virtual environment is that of a virtual function.
        We’ve seen these described in \S \ref{sec:vt_io} as a multiplexed interface into the actual physical connection of the device.
        These interfaces run at line rates, but have fewer receive and transmit queues than the original interface.
        This implies that they can achieve native performance for small workloads that do not saturate their buffers.
        These interfaces have significantly improved performance over the bridged interfaces since the host kernel need not be involved in processing these packets which happens in the card itself instead.
        For the most part, virtual functions may be handled by the operating system or guest OS as if they were any other physical device and passthrough or direct assignment is used to attach them to VMs and containers, respectively.
        % subsubsection hardware_networking (end)
    % subsection expt_networking (end)
    \subsection{Software Environment} % (fold)
    \label{sub:software_environment}
    The operating system used in this study needed to have a balance of stability, advanced features, and performance so a Long Term Support LTS version of Ubuntu, 14.04.3 was chosen.
    The Linux 3.18.20 kernel was selected for both the host and guest OS due to a set of factors affecting usability and performance.
    Choosing which Linux kernel version to use for this study was complicated by factors that were not known until system configuration.
    It was already understood prior to configuration that Docker was not supported in kernel versions prior to 3.10 [reference?] which helped to narrow down the possibilities.
    One of the side-goals of this study was to use as much standard and open software as possible so that the kernel and system configurations could be easily reproduced by other investigators.
    This goal had a substantial influence on the choice of kernel due to the performance impact of Docker's storage driver.
    By default, Docker currently  uses the AUFS filesystem for its back-end storage driver.
    This module allows the classical union filesystem approach of masking important host files and providing private copies of system files to each container.
    Other options for this driver include devicemapper, zfs, btrfs, and overlayfs.
    The AUFS driver has been deprecated in the Linux kernel so it is not available upstream which disqualifies it from any forward-looking uses.
    The devicemapper driver, while ubiquitous, shows significant performance degradation and usability issues disqualifying it as well.
    Both zfs and btrfs have stability issues and are not yet standard filesystem drivers so they were also disqualified.
    The remaining choice was overlayfs which was recently upstreamed into the 3.18 kernel and seems to be the choice for Docker storage driver going forward until zfs and btrfs become standard [ reference here re: overlayfs RedHat study].
    Further limitations, while not as impactful as the choice of the 3.18 kernel include the availability of preempt-rt patches for the kernel.

        \subsubsection{Kernel Configuration} % (fold)
        \label{ssub:kernel_configuration}
        One of the steps involved in tuning the RT variant of our kernel was to apply a specific set of kernel configuration choices during the kernel build process.
        The kernel shipped with Ubuntu 14.04.3 was version 3.19.0-25-generic.
        That kernels default configuration (.config) was used as the basis for the configuration and building of the test kernel version 3.18.20. 
        This default kernel configuration omits even simple omtimizations such as disabling CPU frequency scaling, and enabling a pre-emptible kernel (CONFIG\_PREEMPT), but the default kernel configuration is probably the most common on servers that haven't done significant performance tuning and optimizations so it seemed appropriate. 
        The "performance" kernel used was the 3.18.20-rt18 kernel which is the 3.18.20 kernel with the 3.18.20-rt18 patches, dated 2015-08-11, from [https://www.kernel.org/pub/linux/kernel/projects/rt/3.18/older/] applied.
        The initial kernel configuration used was that of the 3.18.20 kernel. 
        Only a few important parameters of the kernel were modified to tune the systems for performance with the preempt-rt patch.
        Kernel CONFIG modifications are described in Table XXYY.  : [Insert CONFIG\_ table here?]\\
        Table: \\
        CONFIG\_PARAM1 | effect1 \\ 
        CONFIG\_PARAM2 | effect2 \\ 
        % subsubsection kernel_configuration (end)

        \subsubsection{Kernel Boot Parameters} % (fold)
        \label{ssub:kernel_params}
        Another important mechanism for tuning a kernel is to modify the parameters passed to the kernel at boot time.  
        [ Insert table here?  Describe some of the important parameters] \\ 
        One of the most important tuning parameters in a virtual machine host relates to the level of oversubscription for each physical CPU.
        Systems with low performance requirements may stack multiple guest vCPUs (virtual CPUs) on each physical CPU.  This stacking can lead to multiple vCPUs from unrelated virtual machines sharing the pCPU or just host processes running on the pCPU assigned to the guest.
        Either of these scenarios can have a large impact on guest latency.
        If a pCPU is running another task when a guest vCPU is not in the current context, the additional latency required to change context to the guest and resumt the guest OS operation can be a significant source of latency.
        These resource conflicts can be all but eliminated by "unplugging" pCPUs assigned to a guest from the host scheduler with the isolcpus=X kernel boot parameters.
        Assigning a pCPU to the isolcpus list, like isolcpus=2, will remove that pCPU from the kernel scheduler's CPU pool, preventing the kernel scheduler from running any processes there.
        The isolated CPUs can still be used to run user processes with Linux utilities like taskset or numactl, but will remain quiescent until that happens.
        Scalability of a system with isolated CPUs is reduced, but in an era of server processors with up to 18 cores [Intel Xeon reference here, Xeons may be moving toward something like many-core Knights Landing], the impact of dedicating individual pCPUs to latency-sensitive processes is reduced.

        Hugepages for reduction in TLB misses [ Huge TLB paper reference] - Again, huge memory availability leads to not needing to share memory.  \\
        % subsubsection kernel_params (end)

        \subsubsection{Building a Virtual Machine} % (fold)
        \label{ssub:build_vm}
        The image used for virtual machine testing was based on a raw 16 GB disk image created with the command line tool \lstinline{qemu-img}.
        Ubuntu server 14.04.3 was then installed to the image from the ISO file and only the OpenSSH package was selected during the installation.  
        After Ubuntu was installed, the packages for vim, ethtool, screen, qemu-kvm, exuberant-ctags, apparmor, bridge-utils, and libpcap-dev were installed in the VM to keep it consistent with the host installation.  

        % subsubsection build_vm (end)

        \subsubsection{QEMU and hypervisor parameters} % (fold)
        \label{ssub:qemu_params}
        QEMU is responsible for device emulation so this is where it is important to set up the virtual machine to be as performant as possible.
        For optimal performance inside our tuned virtual machine we launch qemu with the --mem-prealloc flag which causes qemu to allocate all of the memory when the virtual machine is initialized. 
        This means that a virtual machine always uses the total amount of memory allocated to it at minimum.
        Although this will increase the resource requirements of these systems, there is a significant performance impact to allowing memory pages belonging to the VM to be swapped out, which will reduce the benefit of using shadow page tables.
        % subsubsection qemu_params (end)
        \subsubsection{Docker parameters} % (fold)
        \label{ssub:docker_params}
        The Docker environment is logically separated into building with \lstinline{docker build}, back-end management performed by the Docker daemon, and the \lstinline{docker run} command that actually instantiates containers from images and assigns the appropriate cgroups and namespacing to the containers.
        The Docker daemon essentially sets up the software environment for the containers, specifically their filesystems, libraries, and avaialble binaries.  
        Along with the files available to the container, the daemon also manages cgroups and namespaces to properly control the container's resoruces and limit its scope.  
        The docker run command is responsible for requesting resources and privileges for the container as it is instantiated.

        The image building process of Docker is controlled by the \lstinline{docker build} command line tool.  
        This tool takes recipe files known as Dockerfiles \autocite{_dockerfile_1} and constructs the image based on instructions therein.
        A Dockerfile usually specifies the base image that should be used for the build along with setting environment variables and installing necessary packages and binaries to the container's filesystem. It is consumed by the \lstinline{docker build} tool and the image is constructed as the composite overlay of each step in the build process \autocite{_docker_build_1}.
        All of the containers used herein were based on the official Debian image, \lstinline{debian:wheezy}, which is based on the latest release of Debian 7: Wheezy.  
        The image was pulled from the Docker.io repository on September 1, 2015 with image ID bbe78c1a5a53.  The debian image was chosen since it has a very small starting size of only 85 MB and no additional tools provided by larger base images were necessary.  In retrospect, this decision creates a small discrepancy in the comparison of these containers to the virtual machines used herein since the VMs were all using Ubuntu 14.04.3.  Since the userpace tools of the distro are not the subject of this investigation, it was decided that the base container image of Debian would not cause any issues since the kernel function inside the containers was of interest and that version is common among all of the environments used.  
        The image created for benchmarking was called netbench and created with the Dockerfile.netbench [ reference here??].  It only pulled the debian base image, applied some labels and installed netperf.  Later that same image was used with iperf by mounting a host volume containing the iperf directory which was then copied into the container's filesystem.
        
        The daemon has a number of parameters that may be modified to tune parameters such as available cgroup cpu sets, bridged networking, and the storage driver used for container filesystems.
        In this study, the docker daemon was launched with mostly standard parameters but for the following exceptions.
        As we've discussed in \S \ref{sub:software_environment}, we chose to use the overlayfs storage driver, requiring the docker daemon to be launched with --storage-driver=overlay.  
        Additionally, Docker's default bridge, docker0, was configured to draw on a pool of IP addresses from the subnet 192.168.42.240/28 for its bridged virtual ethernet interfaces.
        
        The Docker run command provides a substantial level of flexibility and power to the user in controlling the resources available to containers.
        It can be used to give the container complete root privileges, essentially defeating the container's isolation, but it can also be used to give very specific capabilities with the 
        There are so many options that the docker run command can perform that the discussino is outside the scope of this document.  Our modifications herein are as follows.
        All containers were run with non-persistent filesystems by using the --rm option in the docker run line.  This had the effect of removing the container's filesystem overlay after it exits, preventing any filesystem modifications between runs.  Indeed, this is one of the advantages of conatiners in obtaining consistent performance since the container filesystem is reloaded from the base image at every launch.  Containers were also run with the flags \lstinline{-i -t} or \lstinline{-it}, which requested that an interactive tty be allocated to the container while it is running.  This has the effect of a small additional overhead for the terminal process, but this is consistent with the default operation of Docker.  
        Containers are all launched with a specified MAC address for their bridge interface to remove the need to refresh ARP tables with new, randomized MAC addresses.
        % subsubsection docker_params (end)

    
    % subsection software_environment (end)

% section experimental_setup (end)

\section{Experimental Procedure} % (fold)
\label{sec:experimental_procedure}
Given the experimental setup described in \S \ref{experimental_setup}, the performance of virtual machines and containers could be compared.  
We wanted to compare the performance of the systems with RT tuning to those without.
The performance of latency-sensitive network workloads are often not bound by memory or CPU, but by their ability to process I/O traffic.
We concentrated our testing on network-related benchmarks including netperf and iperf.  
The network paths that were tested were mostly layer 4 related including both TCP and UDP flows.

Using netperf version 2.7.0 \autocite{_netperf_1, _netperf_2}, tests completed comprised the default bandwidth test TCP\_STREAM, TCP\_RR, UDP\_STREAM, and UDP\_RR.\\  
(TODO: insert table here to describe the subtests and maybe a topology diagram too. ) \\

% section experimental_procedure (end)
